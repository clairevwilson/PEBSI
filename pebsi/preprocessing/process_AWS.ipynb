{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data Processing\n",
    "This Jupyter notebook contains code to process automatic weather station (AWS) data to a standardized format for the PyGEM-EB model. The AWS dataset should be in a single comma/tab-separated file containing all timesteps and all data variables. If the data is not in that format, first use preprocess_AWS.ipynb. Note that this code may not be comprehensive for all errors that arise from the formatting of a specific dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import xarray as xr\n",
    "import logging\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up: Define variables\n",
    "Fill out the cell below to set up the glacier being accessed and the filepaths.\n",
    "\n",
    "### Lines you should edit are marked with three asterisks (***). Use CTRL+F to highlight all instances and ease usage of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========== Check all the variables below this line for a new glacier ===========\n",
    "# STATION INFORMATION   \n",
    "glac_name = 'kahiltna'          # *** Glacier name for output file corresponding to PEBSI/data/glacier_metadata    \n",
    "station_name = '2008'           # *** Descriptive name for log and output (e.g. site name, year, etc.)\n",
    "elev = 2970                     # *** Elevation of AWS [m a.s.l.]\n",
    "lat = 63.07                     # *** Latitude of AWS [decimal degrees]\n",
    "lon = -151.17                   # *** Longitude of AWS [decimal degrees]\n",
    "station_type = 'on-ice'         # *** Type of station (on-ice, off-ice, or debris)\n",
    "\n",
    "# TIMEZONE\n",
    "timezone = 'GMT-08'             # *** Timezone of output data (should be local time)\n",
    "input_timezone = 'GMT-08'       # *** Time zone of input data\n",
    "\n",
    "# DATA FILEPATHS\n",
    "data_fn = 'Raw/kahiltna/denali2008.xls'                     # *** Filename of input data (relative to data_fp)\n",
    "\n",
    "# =========== Below this line, you do not need to make any edits ===========\n",
    "# OUTPUT FILEPATHS\n",
    "data_fp = '../../../climate_data/AWS/'                      # Filepath to the folder of input data\n",
    "export_fp = '../../../climate_data/AWS/Processed/'          # Filepath to the folder to save this data\n",
    "export_fn = export_fp + glac_name +'/'\n",
    "if not os.path.exists(export_fn):\n",
    "    os.mkdir(export_fn)                                     # Make folder for this glacier\n",
    "export_fn += glac_name + station_name + '.csv'              # Name of output file\n",
    "metadata_fn = '../../data/aws_metadata.txt'                 # Name of metadata file\n",
    "if not os.path.exists(metadata_fn):   \n",
    "    print('Creating metadata file for weather stations')             \n",
    "    with open(metadata_fn, 'w') as f:\n",
    "        f.write('glacier\\tstation\\televation\\tlatitude\\tlongitude\\ttype\\n')         # Write metadata text file header\n",
    "\n",
    "# MINIMUM DATA PERCENTAGE\n",
    "data_min_percentage = 0.8       # Below this threshold of data coverage, specific variables will be thrown out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "From the output of the first cell, make sure the columns have been properly loaded. \n",
    "\n",
    "The cell below contains a dictionary with the possible for each variable. If the column names you want to use are missing, add those to the \"names\" dictionary.\n",
    "\n",
    "Also specify the name of the time column and any NaN values specific to this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Year' 'Day' 'Month' 'Day.1' 'Unnamed: 4' 'Decimal Day' 'Hour' 'AvgAirT'\n",
      " 'AvgAirRH' 'Avg Solar Rad' 'Wind speed' 'Wind Speed' 'Avg Wind dir'\n",
      " 'Wind Direction' 'Wind speed.1' 'Wind speed.2' 'Unnamed: 16']\n",
      "   Year  Day Month  Day.1  Unnamed: 4  Decimal Day  Hour AvgAirT AvgAirRH  \\\n",
      "1  2008  128   May    7.0         NaN          NaN  2400  -3.078    49.09   \n",
      "2  2008  128   May    7.0         NaN          NaN  2000  -5.064    54.52   \n",
      "3  2008  128   May    7.0         NaN          NaN  2100  -6.022    56.32   \n",
      "4  2008  128   May    7.0         NaN          NaN  2200   -8.86     71.3   \n",
      "5  2008  128   May    7.0         NaN          NaN  2300    -9.4    66.86   \n",
      "\n",
      "  Avg Solar Rad Wind speed Wind Speed Avg Wind dir Wind Direction  \\\n",
      "1           418          0          0            0              0   \n",
      "2           344      1.073      1.027        295.2          16.01   \n",
      "3         196.2      1.283      1.036        314.2          35.54   \n",
      "4         26.26      1.081      0.877        343.3          35.24   \n",
      "5         4.297      1.455      1.384        311.6          17.88   \n",
      "\n",
      "  Wind speed.1 Wind speed.2 Unnamed: 16  \n",
      "1            0            0       May 7  \n",
      "2      2.08162      1.99238       May 7  \n",
      "3      2.48902      2.00984       May 7  \n",
      "4      2.09714      1.70138       May 7  \n",
      "5       2.8227      2.68496       May 7  \n"
     ]
    }
   ],
   "source": [
    "# Read in the data and make sure the columns were correctly loaded\n",
    "# Note: this step is likely to cause errors that can be fixed by adjusting the input arguments, for example delim_whitespace\n",
    "rows_to_skip = 2     # Number of rows that contain text at the beginning of the file\n",
    "df = pd.read_excel(data_fp + data_fn,skiprows=rows_to_skip,sheet_name='Hourly AWS').iloc[1:]  # May need to change sep to \\t if tab-separated\n",
    "print(df.columns.to_numpy())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              datetime  Hour\n",
      "7  2008-05-08 01:00:00   1.0\n",
      "8  2008-05-08 02:00:00   2.0\n",
      "9  2008-05-08 03:00:00   3.0\n",
      "10 2008-05-08 04:00:00   4.0\n",
      "11 2008-05-08 05:00:00   5.0\n",
      "                    Wind speed AvgAirT AvgAirRH Avg Solar Rad\n",
      "datetime                                                     \n",
      "2008-05-08 01:00:00      1.598   -9.45    65.92             0\n",
      "2008-05-08 02:00:00      1.681  -10.09    68.55             0\n",
      "2008-05-08 03:00:00      0.946  -10.57     74.6             0\n",
      "2008-05-08 04:00:00      1.586  -11.15     75.4             0\n",
      "2008-05-08 05:00:00      1.069  -11.16     73.9             0\n",
      "...                        ...     ...      ...           ...\n",
      "2009-05-05 10:00:00      2.188  -3.957     71.3         312.2\n",
      "2009-05-05 11:00:00      2.776  -2.993     70.7         423.6\n",
      "2009-05-05 12:00:00      2.193  -1.054       70         574.4\n",
      "2009-05-05 13:00:00      1.082   2.623    58.72         665.3\n",
      "2009-05-05 14:00:00      1.006   3.108    57.28           709\n",
      "\n",
      "[8702 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df.rename(columns={'Day':'doy','Day.1':'day','Month':'month_name'})\n",
    "df = df.dropna()\n",
    "\n",
    "df['Hour'] = df['Hour'].astype(float) / 100\n",
    "df['month'] = pd.to_datetime(df['month_name'], format='%b', errors='coerce').dt.month\n",
    "df['datetime'] = pd.to_datetime(df[['Year','month','day','Hour']])\n",
    "print(df[['datetime','Hour']].head())\n",
    "df.index = df['datetime']\n",
    "df = df[['Wind speed','AvgAirT','AvgAirRH','Avg Solar Rad']]\n",
    "df.to_csv(data_fp + 'Raw/kahiltna/kahiltna_cleaned.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>RECORD</th>\n",
       "      <th>Par_FarRed_1_Avg</th>\n",
       "      <th>FarRed_1_Avg</th>\n",
       "      <th>Par_FarRed_2_Avg</th>\n",
       "      <th>FarRed_2_Avg</th>\n",
       "      <th>TargetTemp_Avg</th>\n",
       "      <th>AirTC_Avg</th>\n",
       "      <th>RH</th>\n",
       "      <th>WS_ms_Avg</th>\n",
       "      <th>...</th>\n",
       "      <th>I_in_chg</th>\n",
       "      <th>Chg_TmpC</th>\n",
       "      <th>Chg_State</th>\n",
       "      <th>Chg_Source</th>\n",
       "      <th>Ck_Batt</th>\n",
       "      <th>CNR4TC_Avg</th>\n",
       "      <th>CNR4TC_Std</th>\n",
       "      <th>TFC_TmpCAvg</th>\n",
       "      <th>XAngle</th>\n",
       "      <th>YAngle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-04-21 18:20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>8.42</td>\n",
       "      <td>71.48</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6.707</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.919132E+14</td>\n",
       "      <td>4.468999E+14</td>\n",
       "      <td>-7999</td>\n",
       "      <td>-7999</td>\n",
       "      <td>-7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-04-21 18:40:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.77168E+15</td>\n",
       "      <td>3.38405E+15</td>\n",
       "      <td>-7999</td>\n",
       "      <td>-7999</td>\n",
       "      <td>-7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-04-21 18:50:00</td>\n",
       "      <td>2</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.921588E+15</td>\n",
       "      <td>8.914693E+15</td>\n",
       "      <td>-7999</td>\n",
       "      <td>-7999</td>\n",
       "      <td>-7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-04-21 19:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.29053E+15</td>\n",
       "      <td>1.370166E+16</td>\n",
       "      <td>-7999</td>\n",
       "      <td>-7999</td>\n",
       "      <td>-7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-04-22 04:10:00</td>\n",
       "      <td>4</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>-5.545627</td>\n",
       "      <td>-6.246</td>\n",
       "      <td>89.5</td>\n",
       "      <td>1.173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-2.539</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.490592</td>\n",
       "      <td>0.03328255</td>\n",
       "      <td>-7999</td>\n",
       "      <td>-7999</td>\n",
       "      <td>-7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17646</th>\n",
       "      <td>2025-08-22 16:10:00</td>\n",
       "      <td>17644</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>0.696917</td>\n",
       "      <td>3.878</td>\n",
       "      <td>83.4</td>\n",
       "      <td>1.032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099</td>\n",
       "      <td>2.862</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.343809</td>\n",
       "      <td>0.121217</td>\n",
       "      <td>-7999</td>\n",
       "      <td>-7999</td>\n",
       "      <td>-7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17647</th>\n",
       "      <td>2025-08-22 16:20:00</td>\n",
       "      <td>17645</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>0.568126</td>\n",
       "      <td>3.94</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138</td>\n",
       "      <td>3.174</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.616972</td>\n",
       "      <td>0.024683</td>\n",
       "      <td>-7999</td>\n",
       "      <td>-7999</td>\n",
       "      <td>-7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17648</th>\n",
       "      <td>2025-08-22 16:30:00</td>\n",
       "      <td>17646</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>0.617294</td>\n",
       "      <td>4.136</td>\n",
       "      <td>86.4</td>\n",
       "      <td>0.803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068</td>\n",
       "      <td>3.226</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.79472</td>\n",
       "      <td>0.058635</td>\n",
       "      <td>-7999</td>\n",
       "      <td>-7999</td>\n",
       "      <td>-7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17649</th>\n",
       "      <td>2025-08-22 16:40:00</td>\n",
       "      <td>17647</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>0.666338</td>\n",
       "      <td>3.726</td>\n",
       "      <td>84.7</td>\n",
       "      <td>0.596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067</td>\n",
       "      <td>3.298</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.848512</td>\n",
       "      <td>0.096975</td>\n",
       "      <td>-7999</td>\n",
       "      <td>-7999</td>\n",
       "      <td>-7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17650</th>\n",
       "      <td>2025-08-22 16:50:00</td>\n",
       "      <td>17648</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>NAN</td>\n",
       "      <td>0.793739</td>\n",
       "      <td>4.347</td>\n",
       "      <td>85.1</td>\n",
       "      <td>0.006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065</td>\n",
       "      <td>3.502</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.247242</td>\n",
       "      <td>0.089238</td>\n",
       "      <td>-7999</td>\n",
       "      <td>-7999</td>\n",
       "      <td>-7999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17649 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TIMESTAMP RECORD Par_FarRed_1_Avg FarRed_1_Avg  \\\n",
       "2      2025-04-21 18:20:00      0              NAN          NAN   \n",
       "3      2025-04-21 18:40:00      1              NAN          NAN   \n",
       "4      2025-04-21 18:50:00      2              NAN          NAN   \n",
       "5      2025-04-21 19:00:00      3              NAN          NAN   \n",
       "6      2025-04-22 04:10:00      4              NAN          NAN   \n",
       "...                    ...    ...              ...          ...   \n",
       "17646  2025-08-22 16:10:00  17644              NAN          NAN   \n",
       "17647  2025-08-22 16:20:00  17645              NAN          NAN   \n",
       "17648  2025-08-22 16:30:00  17646              NAN          NAN   \n",
       "17649  2025-08-22 16:40:00  17647              NAN          NAN   \n",
       "17650  2025-08-22 16:50:00  17648              NAN          NAN   \n",
       "\n",
       "      Par_FarRed_2_Avg FarRed_2_Avg TargetTemp_Avg AirTC_Avg     RH WS_ms_Avg  \\\n",
       "2                  NAN          NAN            NAN      8.42  71.48         0   \n",
       "3                  NAN          NAN            NAN       NAN    NAN         0   \n",
       "4                  NAN          NAN            NAN       NAN    NAN         0   \n",
       "5                  NAN          NAN            NAN       NAN    NAN         0   \n",
       "6                  NAN          NAN      -5.545627    -6.246   89.5     1.173   \n",
       "...                ...          ...            ...       ...    ...       ...   \n",
       "17646              NAN          NAN       0.696917     3.878   83.4     1.032   \n",
       "17647              NAN          NAN       0.568126      3.94   85.0     1.493   \n",
       "17648              NAN          NAN       0.617294     4.136   86.4     0.803   \n",
       "17649              NAN          NAN       0.666338     3.726   84.7     0.596   \n",
       "17650              NAN          NAN       0.793739     4.347   85.1     0.006   \n",
       "\n",
       "       ... I_in_chg Chg_TmpC Chg_State Chg_Source Ck_Batt    CNR4TC_Avg  \\\n",
       "2      ...        0    6.707         0          0       0  5.919132E+14   \n",
       "3      ...        0     8.33         0          0       0   1.77168E+15   \n",
       "4      ...        0     9.14         0          0       0  1.921588E+15   \n",
       "5      ...        0     9.63         0          0       0   2.29053E+15   \n",
       "6      ...     0.03   -2.539         1          1       0     -4.490592   \n",
       "...    ...      ...      ...       ...        ...     ...           ...   \n",
       "17646  ...    0.099    2.862         1          1       0      3.343809   \n",
       "17647  ...    0.138    3.174         3          1       0      3.616972   \n",
       "17648  ...    0.068    3.226         3          1       0       3.79472   \n",
       "17649  ...    0.067    3.298         3          1       0      3.848512   \n",
       "17650  ...    0.065    3.502         3          1       0      4.247242   \n",
       "\n",
       "         CNR4TC_Std TFC_TmpCAvg XAngle YAngle  \n",
       "2      4.468999E+14       -7999  -7999  -7999  \n",
       "3       3.38405E+15       -7999  -7999  -7999  \n",
       "4      8.914693E+15       -7999  -7999  -7999  \n",
       "5      1.370166E+16       -7999  -7999  -7999  \n",
       "6        0.03328255       -7999  -7999  -7999  \n",
       "...             ...         ...    ...    ...  \n",
       "17646      0.121217       -7999  -7999  -7999  \n",
       "17647      0.024683       -7999  -7999  -7999  \n",
       "17648      0.058635       -7999  -7999  -7999  \n",
       "17649      0.096975       -7999  -7999  -7999  \n",
       "17650      0.089238       -7999  -7999  -7999  \n",
       "\n",
       "[17649 rows x 46 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use CNR4TC_Avg to calculate longwave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill out after executing above to check the variable names for time and precipitation\n",
    "time_vn = 'TIMESTAMP' # *** Variable name of time column\n",
    "assert time_vn in df.columns, 'Fill out time variable name'\n",
    "\n",
    "# Can leave precip_vn empty if there is no precip or if the data is already hourly (if subhourly, precipitation needs to be resampled differently)\n",
    "precip_vn = 'Rain_mm_Tot'\n",
    "\n",
    "# Add the names of your columns to the names dict below if they are not already present\n",
    "names = {'temp':['site_temp_USGS','temperature','Tair_aws','temp','TA_2.0m','T','AirTC_Avg','Temperature'],\n",
    "            'tp':['Precip_Weighing_Incremental','precipitation','Ptotal_aws','tp','P','Rain_mm_Tot'],\n",
    "            'rh':['RelHum','RH','rh','rH','RH_aws','RH_2.0m'],\n",
    "            'SWin':['RadiationIn','SWin','SWin_aws','SW_IN','SWUpper_Avg'],\n",
    "            'SWout':['RadiationOut','SWout','SWout_aws','SW_out','SW_OUT','SWLower_Avg'],\n",
    "            'LWin':['LWRadiationIn','LWin','LWin_aws','LW_in','LW_IN','Lwin','LWUpper_Avg'],\n",
    "            'LWout':['LWRadiationOut','LWout','LWout_aws','LW_OUT','LWLower_Avg'],\n",
    "            'NetRad':['NetRad'],\n",
    "            'wind':['WindSpeed','wind','Wind','ws_aws','WS','WS_ms_Avg'],\n",
    "            'winddir':['VecAvgWindDir','WindDir','Winddir','winddir','WD'],\n",
    "            'sp':['barom','sp','press','Press_aws','Barom','BV_BP_Avg','Pressure'],\n",
    "            'tcc':['cloud_fraction','tcc','CCF','CCF_aws'],\n",
    "            'dtemp':['dtemp','dewpoint_temp']}\n",
    "\n",
    "# If there are unique nan values in this data, fill them out here\n",
    "nan_values = [-888.8800,-888.9]\n",
    "# filter out those nans\n",
    "for nan_value in nan_values:\n",
    "    df = df.where(df != nan_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Space for extra preprocessing if opening the file isn't enough: =====\n",
    "# n = len(df['TIMESTAMP'])\n",
    "# store = []\n",
    "# for i in range(n):\n",
    "#     datetime = str(df.index[i]) +' '+ df['TIMESTAMP'][i]\n",
    "#     store.append(datetime)\n",
    "# df['TIMESTAMP'] = store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== If precipitation data is cumulative, use this code to make it differential =====\n",
    "# orig = df[precip_vn].to_numpy().copy()\n",
    "# orig[1:] = np.diff(orig)\n",
    "# print(orig)\n",
    "# df[precip_vn] = orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Launch logger\n",
    "The logger stores information regarding the process and is saved alongside the final output .csv. You do not need to change anything in this block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get base logger\n",
    "base_logger = logging.getLogger()\n",
    "\n",
    "# Create logger which is only updated if a line has not already been documented\n",
    "class UniqueLogger:\n",
    "    def __init__(self, logger):\n",
    "        self.logger = logger\n",
    "        self.logged_messages = set()\n",
    "        self.logger.setLevel(logging.DEBUG)\n",
    "\n",
    "    def info(self, msg):\n",
    "        if msg not in self.logged_messages:\n",
    "            self.logger.info(msg)\n",
    "            self.logged_messages.add(msg)\n",
    "\n",
    "# Check if log filepath already exists; if so, overwrite\n",
    "export_logger_fn = export_fn.replace('csv','log')\n",
    "if os.path.exists(export_logger_fn):\n",
    "    os.remove(export_logger_fn)\n",
    "\n",
    "# Add log filepath to logger and get unique logger\n",
    "fhandler = logging.FileHandler(filename=export_logger_fn)\n",
    "base_logger.addHandler(fhandler)\n",
    "logger = UniqueLogger(base_logger)\n",
    "\n",
    "# Initiate logger\n",
    "today = str(pd.Timestamp.today()).replace('-','_')[0:10]\n",
    "logger.info(f'Data for {glac_name} prepared on {today}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Resample to hourly\n",
    "Add the time index to the dataframe. If the original data has a sub-hourly frequency, resample by taking averages of each variable, with the exception of precipitation which is summed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: add start and end time to clip the data\n",
    "# force_dates = False\n",
    "force_dates = ['2025-04-22 04:00','2025-08-22 12:00']         # Fill with datetime strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set time as the dataframe index and remove the time column\n",
    "data_start = pd.to_datetime(df[time_vn].iloc[0])\n",
    "data_end = pd.to_datetime(df[time_vn].to_numpy()[-1])\n",
    "freq = pd.to_datetime(df[time_vn].iloc[1]) - data_start\n",
    "df = df.set_index(pd.to_datetime(df[time_vn]))\n",
    "\n",
    "# Adjust timezone of index if necessary\n",
    "if timezone != input_timezone:\n",
    "    time_diff = float(timezone[-3:]) - float(input_timezone[-3:])\n",
    "    df = df.set_index(pd.to_datetime(df.index) + pd.Timedelta(hours=time_diff))\n",
    "\n",
    "# Clip data to forced dates\n",
    "if force_dates:\n",
    "    data_start = pd.to_datetime(force_dates[0])\n",
    "    data_end = pd.to_datetime(force_dates[1])\n",
    "    df = df.loc[data_start:data_end]\n",
    "\n",
    "# Log the time\n",
    "logger.info(f'Data extends from {data_start} to {data_end} with frequency {freq.seconds / 60} min')\n",
    "ntimesteps = np.shape(pd.date_range(data_start,data_end,freq='h'))[0]\n",
    "df = df.drop(time_vn,axis=1).astype(float)\n",
    "\n",
    "# Resample hourly\n",
    "df_ = df\n",
    "if freq.seconds / 3600 < 1:\n",
    "    cols_noP = np.delete(df_.columns.to_numpy(),np.where(df_.columns.to_numpy()==precip_vn))\n",
    "    df = df_[cols_noP].resample('h').mean()\n",
    "    df['tp'] = df_[precip_vn].resample('h').sum()\n",
    "    df = df.loc[data_start:data_end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Rename variables\n",
    "The following code should rename inconsistent naming to that used in PyGEM-EB. It will print any variable names that were passed from the original file but were not renamed. Check this list to make sure this list doesn't contain any data you need, as it will be removed in the next step.\n",
    "\n",
    "! If this list contains a data variable you need, the printed name was not included in the list of possible options. Uncomment the block of code labeled 'UPDATE NAMES', add the corresponding variable names, and rerun the renaming block. (Or manually add these names to the 'names' variable above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables were not renamed, including:\n",
      "['RECORD', 'Par_FarRed_1_Avg', 'FarRed_1_Avg', 'Par_FarRed_2_Avg', 'FarRed_2_Avg', 'TargetTemp_Avg', 'WS_ms_Max', 'WS_ms_WVc(1)', 'WS_ms_WVc(2)', 'T109_C_Avg', 'SWUpper_Max', 'SWLower_Max', 'LWUpper_Max', 'LWLower_Max', 'SWUpper_Min', 'SWLower_Min', 'LWUpper_Min', 'LWLower_Min', 'SWUpper_Std', 'SWLower_Std', 'LWUpper_Std', 'LWLower_Std', 'VBatt', 'IBatt', 'ILoad', 'V_in_chg', 'I_in_chg', 'Chg_TmpC', 'Chg_State', 'Chg_Source', 'Ck_Batt', 'CNR4TC_Avg', 'CNR4TC_Std', 'TFC_TmpCAvg', 'XAngle', 'YAngle']\n",
      "Read this list and make sure it only includes variables you want to drop\n"
     ]
    }
   ],
   "source": [
    "# RENAMING\n",
    "drop_vars = [] # Storage for variables to be removed\n",
    "\n",
    "# List all variables\n",
    "all_vars = ['temp','tp','rh','SWin','SWout',\n",
    "            'LWin','LWout','wind','winddir',\n",
    "            'sp','tcc','NetRad','dtemp']\n",
    "\n",
    "# Loop through dataset variables and try to rename\n",
    "for var in df.columns.to_numpy():\n",
    "    renamed = False\n",
    "\n",
    "    # Loop through each actual variable and check if the column exists\n",
    "    for var_check in all_vars:\n",
    "        if var in names[var_check]:\n",
    "            # Match found made: rename variable\n",
    "            df = df.rename(columns={var:var_check})\n",
    "\n",
    "            # Remove this variable such that only one column can exist\n",
    "            all_vars.remove(var_check)\n",
    "\n",
    "            # Store that the variable was renamed\n",
    "            renamed = True\n",
    "\n",
    "    # Drop variables that were not renamed\n",
    "    if not renamed:\n",
    "        drop_vars.append(var)\n",
    "\n",
    "# Print missing variables\n",
    "if len(drop_vars) > 0:\n",
    "    print('Variables were not renamed, including:')\n",
    "    print(drop_vars)\n",
    "    print('Read this list and make sure it only includes variables you want to drop')\n",
    "else:\n",
    "    drop_vars = [0]\n",
    "\n",
    "# Drop the variables that weren't identified in \"names\"\n",
    "df = df.drop(drop_vars,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Interpolate data and inspect\n",
    "First throw out any data variables that don't meet the minimum data requirement. Then fill minor data holes with interpolation. Then check the data count to look for big data gaps that weren't filled by interpolation. This likely indicates the sensor was down for a period or wasn't installed until some time into the date range. That variable will be thrown out too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through data\n",
    "for var in df.columns:\n",
    "    # Check how many of the timestamps are not NaNs\n",
    "    percent_there = df[var].count() / ntimesteps\n",
    "\n",
    "    # Below minimum data percentage, delete the column\n",
    "    if percent_there < data_min_percentage:\n",
    "        missing_percent = (1-data_min_percentage) * 100\n",
    "        statement = f'Variable {var} removed: missing over {missing_percent:.0f}% of the data'\n",
    "        print(statement)\n",
    "        logger.info(statement)\n",
    "        df = df.drop(columns=var)\n",
    "    \n",
    "# Interpolate to fill remaining gaps\n",
    "df = df.interpolate('linear')\n",
    "\n",
    "# Double check the gaps were filled (long gaps can be missed)\n",
    "for var in df.columns:\n",
    "    # Only check not-full variables with more than 0 data points\n",
    "    if df[var].count() < ntimesteps and df[var].count() > 0:\n",
    "        # Check how much data is still missing\n",
    "        nmissing = ntimesteps - df[var].count()\n",
    "        missing = df[var][df[var].isna()]\n",
    "\n",
    "        if len(missing) > 0:\n",
    "            # Print a warning\n",
    "            start_missing = str(missing.index[0])[0:10]\n",
    "            end_missing = str(missing.index[-1])[0:10]\n",
    "            statement = f'Variable {var} removed: missing {nmissing} values between {start_missing} and {end_missing} after interpolation'\n",
    "            print(statement)\n",
    "            logger.info(statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Check units\n",
    "Check the units of each variable. The best way to do this is manually specify the units of the variables you're using from the input data. The table below contains the units each variable is supposed to be in for the model.\n",
    "\n",
    "| Variable      | Units |\n",
    "| ----------- | ----------- |\n",
    "| Temperature      | C       |\n",
    "| Humidity   | % (0-100)        |\n",
    "| Wind Speed      | m/s       |\n",
    "| Wind Direction   | $\\circ$        |\n",
    "| Precipitation      | m (w.e.)       |\n",
    "| Surface Pressure   | Pa        |\n",
    "| Incoming Shortwave      | J/m$^2$       |\n",
    "| Incoming Longwave   | J/m$^2$        |\n",
    "| Cloud cover      | 0-1 (decimal)       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== If the units are specified in a row of the original dataframe, print and inspect ======\n",
    "# df_units = pd.read_csv(data_fp + data_fn,skiprows=rows_to_skip,delim_whitespace=False) \n",
    "# print(df_units.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['tp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTUAL DATA UNITS (FILL THIS OUT FOR THE VARIABLES IN df)\n",
    "temp_units = 'C'\n",
    "tp_units = 'mm'\n",
    "sp_units = 'hPa'\n",
    "rh_units = '%'\n",
    "wind_units = 'm s-1'\n",
    "winddir_units = 'degrees'\n",
    "SWin_units = 'W m-2'\n",
    "SWout_units = 'W m-2'\n",
    "LWin_units = 'W m-2'\n",
    "LWout_units = 'W m-2'\n",
    "tcc_units = 'decimal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted SWin W m-2-->J m-2\n",
      "Adjusted SWout W m-2-->J m-2\n",
      "Adjusted LWin W m-2-->J m-2\n",
      "Adjusted LWout W m-2-->J m-2\n",
      "Adjusted sp hPa-->Pa\n"
     ]
    }
   ],
   "source": [
    "# Add units of input data to a dictionary\n",
    "units_in = {'temp':temp_units,'rh':rh_units,'SWin':SWin_units,'SWout':SWout_units,'LWin':LWin_units,'LWout':LWout_units,\n",
    "            'wind':wind_units,'winddir':winddir_units,'sp':sp_units,'tp':tp_units,'tcc':tcc_units}\n",
    "\n",
    "# DON'T CHANGE: these are the units needed for the model\n",
    "units_out = {'temp':'C','dtemp':'K','tp':'m','rh':'%',\n",
    "        'SWin':'J m-2','SWout':'J m-2','LWin':'J m-2','LWout':'J m-2',\n",
    "        'tcc':'0-1','wind':'m s-1','winddir':'deg','sp':'Pa'}\n",
    "\n",
    "# Check each variable for common unit differences\n",
    "if 'temp' in df.columns:\n",
    "    if units_in['temp'] == 'K':\n",
    "        df['temp'] = df['temp'] - 273.15\n",
    "        print('Adjusted temp K-->C')\n",
    "        units_in['temp'] = 'C'\n",
    "    elif units_in['temp'] == 'F':\n",
    "        df['temp'] = (df['temp'] - 32)*5/9\n",
    "        print('Adjusted temp F-->C')\n",
    "        units_in['temp'] = 'C'\n",
    "    elif units_in['temp'] != units_out['temp']:\n",
    "        print('! Temperature units do NOT match and were NOT updated: make a manual correction')\n",
    "    \n",
    "if 'rh' in df.columns:\n",
    "    if units_in['rh'] == 'decimal':\n",
    "        df['rh'] = df['rh'] * 100\n",
    "        print('Adjusted RH decimal-->%')\n",
    "        units_in['rh'] = '%'\n",
    "    elif units_in['rh'] != units_out['rh']:\n",
    "        print('! Relative humidity units do NOT match and were NOT updated: make a manual correction')\n",
    "\n",
    "if 'wind' in df.columns:\n",
    "    if units_in['wind'] == 'km hr-1':\n",
    "        df['wind'] = df['wind'] * 1000 / 3600\n",
    "        print('Adjusted wind speed-->m s-1')\n",
    "        units_in['wind'] = 'm s-1'\n",
    "    elif units_in['wind'] != units_out['wind']:\n",
    "        print('! Wind units do NOT match and were NOT updated: make a manual correction')\n",
    "    \n",
    "if 'winddir' in df.columns:\n",
    "    if units_in['winddir'] == 'rad':\n",
    "        df['winddir'] = df['winddir'] * 180/np.pi\n",
    "        print('Adjusted winddir radians-->deg')\n",
    "        units_in['winddir'] = 'deg'\n",
    "    elif units_in['winddir'] != units_out['winddir']:\n",
    "        print('! Wind direction units do NOT match and were NOT updated: make a manual correction')\n",
    "    \n",
    "if 'tcc' in df.columns:\n",
    "    if units_in['tcc'] == '%':\n",
    "        df['tcc'] = df['tcc'] / 100\n",
    "        print('Adjusted tcc %-->0-1')\n",
    "        units_in['tcc'] = '0-1'\n",
    "    elif units_in['tcc'] != units_out['tcc']:\n",
    "        print('! Cloud cover units do NOT match and were NOT updated: make a manual correction')\n",
    "    \n",
    "if 'tp' in df.columns:\n",
    "    if units_in['tp'] == 'm s-1':\n",
    "        df['tp'] = df['tp'] *3600\n",
    "        print('Adjusted tp m/s-->m')\n",
    "        units_in['tp'] = 'm'\n",
    "    elif units_in['tp'] == 'mm':\n",
    "        df['tp'] = df['tp'] / 1000\n",
    "        print('Adjusted tp mm-->m')\n",
    "        units_in['tp'] = 'm'\n",
    "    elif units_in['tp'] != units_out['tp']:\n",
    "        print('! Precipitation units do NOT match and were NOT updated: make a manual correction')\n",
    "\n",
    "for rad in ['SWin','SWout','LWin','LWout']:\n",
    "    if rad in df.columns:\n",
    "        if units_in[rad] == 'W m-2':\n",
    "            df[rad] = df[rad] * 3600\n",
    "            print(f'Adjusted {rad} W m-2-->J m-2')\n",
    "            units_in[rad] = 'J m-2'\n",
    "        elif units_in[rad] != units_out[rad]:\n",
    "            print(f'! {rad} units do NOT match and were NOT updated: make a manual correction')\n",
    "\n",
    "if 'sp' in df.columns:\n",
    "    if units_in['sp'] == 'mmHg':\n",
    "        df['sp'] = df['sp'] * 133.32\n",
    "        print('Adjusted sp mmHg-->Pa')\n",
    "        units_in['sp'] = 'Pa'\n",
    "    elif units_in['sp'] == 'cmHg':\n",
    "        df['sp'] = df['sp'] * 1333.2\n",
    "        print('Adjusted sp cmHg-->Pa')\n",
    "        units_in['sp'] = 'Pa'\n",
    "    elif units_in['sp'] == 'kPa':\n",
    "        df['sp'] = df['sp'] * 1000\n",
    "        print('Adjusted sp kPa-->Pa')\n",
    "        units_in['sp'] = 'Pa'\n",
    "    elif units_in['sp'] in ['mbar','hPa']:\n",
    "        df['sp'] = df['sp'] * 100\n",
    "        units_sp = units_in['sp']\n",
    "        print(f'Adjusted sp {units_sp}-->Pa')\n",
    "        units_in['sp'] = 'Pa'\n",
    "    elif units_in['sp'] != units_out['sp']:\n",
    "        print('! Surface pressure units do NOT match and were NOT updated: make a manual correction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Reasonable value filters\n",
    "Pass over each data variable and remove any unreasonable values by setting them to a prescribed limit. You can choose to 'remove' (any rows with any variables outside of their range are removed) or 'clip' (clips extreme values to their bound). If you want to perform a different operation on any variables, you can add 'method' to the var_bounds dictionary under that variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_bounds = 'remove' # Choose between 'remove' (remove rows with any variable outside of its range) and 'clip' (clip values to their bounds)\n",
    "var_bounds = {'temp':{'low':-60,'high':50},\n",
    "                'dtemp':{'low':-60,'high':30},\n",
    "                'tp':{'low':0,'high':0.15},\n",
    "                'rh':{'low':0,'high':100},\n",
    "                'SWin':{'low':0,'high':1400*3600,'method':'clip'},\n",
    "                'SWout':{'low':0,'high':1400*3600},\n",
    "                'LWin':{'low':0,'high':500*3600},\n",
    "                'LWout':{'low':0,'high':500*3600},\n",
    "                'tcc':{'low':0,'high':1},\n",
    "                'wind':{'low':0,'high':70},\n",
    "                'winddir':{'low':0,'high':360},\n",
    "                'sp':{'low':75000,'high':110000}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 datapoints of temp\n",
      "Removed 0 datapoints of tp\n",
      "Removed 0 datapoints of rh\n",
      "Removed 369 datapoints of SWout\n",
      "Removed 2805 datapoints of LWin\n",
      "Removed 1372 datapoints of LWout\n",
      "Removed 0 datapoints of wind\n",
      "Removed 0 datapoints of sp\n"
     ]
    }
   ],
   "source": [
    "for var in var_bounds:\n",
    "    if var in df.columns:\n",
    "        count_first = df[var].count()\n",
    "\n",
    "        # check if need a special method for this var\n",
    "        if 'method' in var_bounds[var]:\n",
    "            method = var_bounds[var]['method']\n",
    "        else:\n",
    "            method = method_bounds\n",
    "        \n",
    "        # remove or clip the data\n",
    "        if method == 'remove':\n",
    "            df[var] = df[var].where(df[var].between(var_bounds[var]['low'], var_bounds[var]['high']))\n",
    "            n_removed =  count_first - df[var].count()\n",
    "            print(f'Removed {n_removed} datapoints of {var}')\n",
    "\n",
    "            start = df[df.notna().all(axis=1)].index.min()\n",
    "            end = df[df.notna().all(axis=1)].index.max()\n",
    "            df = df.loc[start:end]\n",
    "\n",
    "        elif method == 'clip':\n",
    "            df[var] = df[var].clip(var_bounds[var]['low'], var_bounds[var]['high'])\n",
    "\n",
    "# Check that SWout does not exceed SWin\n",
    "if 'SWout' in df.columns:\n",
    "    df['SWout'] = df['SWout'].mask(df['SWout'] - df['SWin'] > 0, None)\n",
    "\n",
    "if method_bounds == 'remove':\n",
    "    # Interpolate to fill new gaps introduced\n",
    "    df = df.interpolate('linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for remaining gaps\n",
    "assert df.isna().sum().sum() == 0, 'Still have data gaps!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check on wind speed and calculate directional terms if winddir is there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK THE SIGN CONVENTION HERE BASED ON YOUR WIND DIRECTION MEASUREMENTS\n",
    "if 'wind' in df.columns:\n",
    "    if 'winddir' in df.columns:\n",
    "        angle_rad = np.deg2rad(df['winddir'])\n",
    "        df['uwind'] = -df['wind'] * np.sin(angle_rad) # positive is blowing toward the east\n",
    "        df['vwind'] = -df['wind'] * np.cos(angle_rad) # positive is blowing toward the north\n",
    "        df = df.drop(columns='winddir')\n",
    "    else:\n",
    "        # model takes in uwind and vwind so if it is a scalar, just pass uwind\n",
    "        df = df.rename(columns={'wind':'uwind'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final check and export\n",
    "Print the dataframe and plot the data and visually inspect. Look for any weird values and make sure the daily profiles seem about right (e.g., peak sunlight around noon). Finally export the data and metadata!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [temp, rh, uwind, SWin, SWout, LWin, LWout, sp, tp]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df.head(3), df.tail(3)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many variables there are \n",
    "full_vars = []\n",
    "for var in df.columns:\n",
    "    if df[var].count() > 0:\n",
    "        full_vars.append(var)\n",
    "logger.info(f'Data contains: '+', '.join(full_vars))\n",
    "\n",
    "# make subplots\n",
    "nvars = len(full_vars)\n",
    "fig,axis = plt.subplots(nvars,1,figsize=(7,1.5*nvars),sharex=True)\n",
    "\n",
    "# add hour of day column\n",
    "df['hour'] = pd.to_datetime(df.index).hour\n",
    "\n",
    "# loop through and plot variables\n",
    "for i,var in enumerate(full_vars):\n",
    "    var_hourly = []\n",
    "    for hour in np.arange(24):\n",
    "        # select the dataframe by the hour and find the mean\n",
    "        ds_hour = df[df['hour'] == hour]\n",
    "        hourly_mean = np.mean(ds_hour[var])\n",
    "        var_hourly.append(hourly_mean)\n",
    "    axis[i].plot(np.arange(24),var_hourly)\n",
    "    axis[i].set_ylabel(var)\n",
    "    axis[i].set_xlim((0,23))\n",
    "axis[i].set_xlabel('Hour of day')\n",
    "axis[i].set_xticks([0,6,12,18])\n",
    "plt.show()\n",
    "\n",
    "df = df.drop(columns=['hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: drop outgoing fluxes if you want the model to calculate albedo / surface temperature\n",
    "# df = df.drop(columns=['SWout','LWout'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data\n",
    "if 'SWout' in df.columns:\n",
    "    export_fn_use = export_fn.replace('.csv','allrad.csv')\n",
    "else:\n",
    "    export_fn_use = export_fn\n",
    "df.to_csv(export_fn_use)\n",
    "print(f'Saved data to {export_fn_use}')\n",
    "\n",
    "# Store metadata\n",
    "new_line = f'{glac_name}\\t{station_name}\\t{elev}\\t{lat}\\t{lon}\\t{station_type}\\n'\n",
    "\n",
    "# Read existing lines to check if this station is already written\n",
    "with open(metadata_fn, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    existing_lines = set(line.strip() for line in lines[1:])\n",
    "\n",
    "# Write new lines\n",
    "if new_line.split('\\n')[0] not in existing_lines:\n",
    "    with open(metadata_fn, 'a') as f:\n",
    "        f.write(new_line)\n",
    "    print(f'& metadata to {metadata_fn}')\n",
    "else:\n",
    "    print('& metadata is already written')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== DONE! ====="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eb_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
